<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="Look Where It Matters: Training-Free Ultra-HR Remote Sensing VQA - Yunqi Zhou, Chengjie Jiang, Chun Yuan, Jing Li">
  <meta name="description" content="A training-free approach for ultra-high resolution remote sensing visual question answering using adaptive zoom search to efficiently process large-scale satellite imagery.">
  <meta name="keywords" content="remote sensing, visual question answering, ultra-high resolution, training-free, adaptive zoom search, computer vision, satellite imagery, multimodal AI">
  <meta name="author" content="Yunqi Zhou, Chengjie Jiang, Chun Yuan, Jing Li">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="Tsinghua University & CUFE & ECNU">
  <meta property="og:title" content="Look Where It Matters: Training-Free Ultra-HR Remote Sensing VQA">
  <meta property="og:description" content="A training-free approach for ultra-high resolution remote sensing visual question answering using adaptive zoom search to efficiently process large-scale satellite imagery.">
  <!-- <meta property="og:url" content="https://YOUR_DOMAIN.com/look-where-it-matters">
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630"> -->
  <meta property="og:image:alt" content="Look Where It Matters - Research Preview">
  <meta property="article:author" content="Yunqi Zhou">
  <meta property="article:author" content="Chengjie Jiang">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="Remote Sensing">
  <meta property="article:tag" content="Ultra High Resolution Remote Sensing Visual Question Answering">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Look Where It Matters: Training-Free Ultra-HR Remote Sensing VQA via Adaptive Zoom Search">
  <meta name="citation_author" content="Zhou, Yunqi">
  <meta name="citation_author" content="Jiang, Chengjie">
  <meta name="citation_author" content="Yuan, Chun">
  <meta name="citation_author" content="Li, Jing">
  <!-- <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf"> -->
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">

  <title>Look Where It Matters: Training-Free Ultra-HR Remote Sensing VQA | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/png" href="static/images/logo.png">
  <link rel="apple-touch-icon" href="static/images/logo.png">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Look Where It Matters: Training-Free Ultra-HR Remote Sensing VQA via Adaptive Zoom Search",
    "author": [
      {
        "@type": "Person",
        "name": "Yunqi Zhou",
        "affiliation": {
          "@type": "Organization",
          "name": "Central University of Finance and Economics"
        }
      },
      {
        "@type": "Person",
        "name": "Chengjie Jiang",
        "affiliation": {
          "@type": "Organization",
          "name": "Tsinghua University"
        }
      },
      {
        "@type": "Person",
        "name": "Chun Yuan",
        "affiliation": {
          "@type": "Organization",
          "name": "Tsinghua University"
        }
      },
      {
        "@type": "Person",
        "name": "Jing Li",
        "affiliation": {
          "@type": "Organization",
          "name": "East China Normal University"
        }
      }
    ],
    "keywords": ["remote sensing", "visual question answering", "ultra-high resolution", "training-free", "adaptive zoom search", "computer vision", "satellite imagery"],
    "abstract": "With advances in satellite constellations, sensor technologies, and imaging pipelines, ultra-high-resolution (Ultra-HR) remote sensing imagery is becoming increasingly widespread. However, current remote sensing foundation models are ill-suited to such inputs: full-image encoding exhausts token and memory budgets, while resize-based preprocessing loses fine-grained and answer-critical details. In this context, guiding the model look where it matters before prediction becomes crucial. Therefore, we present ZoomSearch, a training-free, plug-and-play pipeline that decouples 'where to look' from 'how to answer' for Ultra-HR Remote Sensing Visual Question Answering (RS-VQA). ZoomSearch combines Adaptive Multi-Branch Zoom Search, which performs a hierarchical search over image patches to localize query-relevant regions, with Layout-Aware Patch Reassembly, which reorganizes the selected patches into a compact, layout-faithful canvas. We conduct comprehensive experiments on Ultra-HR RS-VQA benchmarks MME-RealWorld-RS and LRS-VQA, comparing against (i) strong general foundation models, (ii) remote sensing foundation models, (iii) Ultra-HR RS-VQA methods, and (iv) plug-and-play search-based VQA methods. When integrated with LLaVA-ov, ZoomSearch attains state-of-the-art accuracy across diverse tasks, improving the LLaVA-ov baseline by 26.3% on LRS-VQA and 114.8% on MME-RealWorld-RS. Meanwhile, it achieves much higher inference efficiency, outperforming prior search-based methods by 20–44% in speed.",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://kiki-zyq.github.io/ZS/"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "Remote Sensing"
      },
      {
        "@type": "Thing", 
        "name": "Ultra High Resolution Visual Question Answering"
      }
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-widescreen">
        <div class="columns is-centered">
          <div class="column has-text-centered">
              <div style="text-align: center; margin-bottom: 1rem; font-size: 2rem; line-height: 1; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-weight: 700;">
                <div style="display: inline-flex; align-items: center;">
                  <img src="static/images/logo.png" alt="Logo" style="height: 50px; margin-right: 12px;">
                  <span style="margin: 0; line-height: 1;">Look Where It Matters:</span>
                </div>
                <div style="margin: 0; line-height: 1;">
                  Training-Free Ultra-HR Remote Sensing VQA via Adaptive Zoom Search
                </div>
              </div>



            <div class="is-size-4 publication-authors">
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=h3QTqt8AAAAJ&hl" target="_blank">Yunqi Zhou</a><sup>1*</sup>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=NGizEIYAAAAJ&hl" target="_blank">Chengjie Jiang</a><sup>2*</sup>,</span>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=fYdxi2sAAAAJ" target="_blank">Chun Yuan</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?hl=zh-CN&user=YAG9tSMAAAAJ" target="_blank">Jing Li</a><sup>3†</sup>
                  </span>
                  </div>

                  <div class="is-size-4 publication-authors">
                    <span class="author-block"><sup>1</sup>Central University of Finance and Economics&nbsp;&nbsp;</span>
                    <span class="author-block"><sup>2</sup>Tsinghua University&nbsp;&nbsp;</span>
                    <span class="author-block"><sup>3</sup>East China Normal University</span>
                    <span class="eql-cntrb" style="display:block; margin-top:0.2rem; line-height:1.2;">
                      <small><sup>*</sup>Equal Contribution&nbsp;&nbsp;<sup>†</sup>Corresponding Author</small>
                    </span>
                  </div>

                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2511.20460" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>

                  <span class="link-block">
                    <a href="https://github.com/kiki-zyq/ZoomSearch" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            With advances in satellite constellations, sensor technologies, and imaging pipelines, ultra-high-resolution (Ultra-HR) remote sensing imagery is becoming increasingly widespread. However, current remote sensing foundation models are ill-suited to such inputs: full-image encoding exhausts token and memory budgets, while resize-based preprocessing loses fine-grained and answer-critical details. In this context, guiding the model <strong>look where it matters</strong> before prediction becomes crucial. Therefore, we present <strong>ZoomSearch</strong>, a training-free, plug-and-play pipeline that decouples 'where to look' from 'how to answer' for Ultra-HR Remote Sensing Visual Question Answering (RS-VQA). ZoomSearch combines <strong>Adaptive Multi-Branch Zoom Search</strong>, which performs a hierarchical search over image patches to localize query-relevant regions, with <strong>Layout-Aware Patch Reassembly</strong>, which reorganizes the selected patches into a compact, layout-faithful canvas. We conduct comprehensive experiments on Ultra-HR RS-VQA benchmarks MME-RealWorld-RS and LRS-VQA, comparing against (i) strong general foundation models, (ii) remote sensing foundation models, (iii) Ultra-HR RS-VQA methods, and (iv) plug-and-play search-based VQA methods. When integrated with LLaVA-ov, <strong>ZoomSearch</strong> attains state-of-the-art accuracy across diverse tasks, improving the LLaVA-ov baseline by <strong>26.3%</strong> on LRS-VQA and <strong>114.8%</strong> on MME-RealWorld-RS. Meanwhile, it achieves much higher inference efficiency, outperforming prior search-based methods by <strong>20–44%</strong> in speed.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Introduction Hero Figure -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Overview of ZoomSearch</h2>

          <figure>
            <img 
              src="static/images/pipeline.jpg" 
              alt="ZoomSearch introduction figure"
              style="max-width: 100%; border-radius: 12px; box-shadow: 0 4px 14px rgba(0,0,0,0.15);" 
            />
          </figure>

          <div class="content has-text-justified mt-4">
            <p>
              The top-left part illustrates <strong>Adaptive Multi-Branch Zoom Search</strong>, 
              which progressively explores the image and focuses on regions that are 
              closely related to the text query. 
              The bottom part shows the <strong>scoring mechanism</strong>, where each candidate patch 
              is evaluated by a patch–text relevance score from an external scoring model 
              and a model-evidence signal from the foundation model. 
              The top-right part depicts <strong>Layout-Aware Patch Reassembly</strong>, 
              which reorganizes the selected informative patches into a spatially 
              consistent canvas that preserves their relative and global positions.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Introduction Hero Figure -->

<!-- Experiment Results Section -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container is-max-widescreen">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Experimental Results</h2>
          
          <!-- LRS-VQA Results Table -->
          <div class="content mt-5">
            <h3 class="title is-4">Performance on LRS-VQA Dataset</h3>
           
            
            <div style="overflow-x: auto;">
              <table class="table is-bordered is-striped is-hoverable" style="margin: 0 auto; font-size: 0.85rem;">
                <thead>
                  <tr style="background-color: #f5f5f5;">
                    <th>Method</th>
                    <th>Pub.</th>
                    <th>Max Res.</th>
                    <th>Rural/Urban</th>
                    <th>Count</th>
                    <th>Reasoning</th>
                    <th>Status</th>
                    <th>Category</th>
                    <th>Shape</th>
                    <th>Color</th>
                    <th>Background</th>
                    <th>Avg.</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>Gemini-2.5-Flash</td>
                    <td>-</td>
                    <td>-</td>
                    <td>56.49</td>
                    <td style="color: #28a745; font-weight: 700;">18.49</td>
                    <td>20.40</td>
                    <td style="color: #d4af37; font-weight: 700;">18.69</td>
                    <td>14.81</td>
                    <td>34.17</td>
                    <td>36.08</td>
                    <td>16.11</td>
                    <td>26.91</td>
                  </tr>
                  <tr>
                    <td>GPT-4o</td>
                    <td>-</td>
                    <td>-</td>
                    <td>55.19</td>
                    <td>16.50</td>
                    <td>21.39</td>
                    <td style="color: #28a745; font-weight: 700;">19.22</td>
                    <td>16.26</td>
                    <td style="color: #28a745; font-weight: 700;">39.32</td>
                    <td>47.45</td>
                    <td>18.78</td>
                    <td style="color: #d4af37; font-weight: 700;">29.26</td>
                  </tr>
                  <tr>
                    <td>LLaVA-v1.5-7b</td>
                    <td>NeurIPS'23</td>
                    <td>336</td>
                    <td>53.04</td>
                    <td>11.84</td>
                    <td>20.50</td>
                    <td>11.80</td>
                    <td>15.40</td>
                    <td>31.98</td>
                    <td>39.87</td>
                    <td>19.18</td>
                    <td>25.45</td>
                  </tr>
                  <tr>
                    <td>LLaVA-v1.6-7b</td>
                    <td>-</td>
                    <td>672</td>
                    <td>52.00</td>
                    <td>13.68</td>
                    <td>19.80</td>
                    <td>17.40</td>
                    <td>15.91</td>
                    <td>29.77</td>
                    <td>41.31</td>
                    <td>17.96</td>
                    <td>25.98</td>
                  </tr>
                  <tr>
                    <td>LLaVA-ov-7b</td>
                    <td>TMLR'25</td>
                    <td>384</td>
                    <td>50.08</td>
                    <td>11.68</td>
                    <td>21.80</td>
                    <td>11.20</td>
                    <td>19.15</td>
                    <td>31.98</td>
                    <td>45.49</td>
                    <td>17.14</td>
                    <td>26.07</td>
                  </tr>
                  <tr>
                    <td>Qwen2.5-VL-7b</td>
                    <td>-</td>
                    <td>1000</td>
                    <td>47.12</td>
                    <td>16.18</td>
                    <td>19.50</td>
                    <td>9.20</td>
                    <td>16.31</td>
                    <td>21.81</td>
                    <td style="color: #d4af37; font-weight: 700;">51.76</td>
                    <td>17.96</td>
                    <td>24.98</td>
                  </tr>
                  <tr>
                    <td>LLaVA-HR</td>
                    <td>ICLR'25</td>
                    <td>1536</td>
                    <td>57.11</td>
                    <td>9.67</td>
                    <td>17.60</td>
                    <td>9.10</td>
                    <td>15.20</td>
                    <td>21.02</td>
                    <td>37.91</td>
                    <td>17.96</td>
                    <td>23.30</td>
                  </tr>
                  <tr>
                    <td>GeoChat</td>
                    <td>CVPR'24</td>
                    <td>504</td>
                    <td>61.42</td>
                    <td>11.76</td>
                    <td>16.70</td>
                    <td>6.50</td>
                    <td>8.00</td>
                    <td>21.47</td>
                    <td>17.39</td>
                    <td>11.84</td>
                    <td>19.38</td>
                  </tr>
                  <tr>
                    <td>VHM</td>
                    <td>AAAI'25</td>
                    <td>336</td>
                    <td>56.39</td>
                    <td>12.26</td>
                    <td>18.80</td>
                    <td>13.40</td>
                    <td>17.12</td>
                    <td>31.86</td>
                    <td>46.27</td>
                    <td>12.24</td>
                    <td>26.69</td>
                  </tr>
                  <tr>
                    <td>GeoLLaVA-8K</td>
                    <td>NeurIPS'25</td>
                    <td>8K</td>
                    <td>54.68</td>
                    <td>12.83</td>
                    <td>21.32</td>
                    <td>4.41</td>
                    <td>14.81</td>
                    <td>22.41</td>
                    <td>49.52</td>
                    <td>16.18</td>
                    <td>24.52</td>
                  </tr>
                  <tr>
                    <td>ImageRAG</td>
                    <td>GRSM'25</td>
                    <td>Dynamic</td>
                    <td style="color: #d4af37; font-weight: 700;">58.55</td>
                    <td>13.70</td>
                    <td>21.20</td>
                    <td>10.00</td>
                    <td>21.07</td>
                    <td>33.90</td>
                    <td>45.75</td>
                    <td>19.18</td>
                    <td>27.92</td>
                  </tr>
                  <tr>
                    <td>ZoomEye</td>
                    <td>EMNLP'25</td>
                    <td>Dynamic</td>
                    <td>48.24</td>
                    <td>14.76</td>
                    <td>22.10</td>
                    <td>10.40</td>
                    <td>23.61</td>
                    <td>28.58</td>
                    <td>45.36</td>
                    <td>21.63</td>
                    <td>26.84</td>
                  </tr>
                  <tr>
                    <td>RAP</td>
                    <td>ICML'25</td>
                    <td>Dynamic</td>
                    <td>45.45</td>
                    <td>16.78</td>
                    <td style="color: #d4af37; font-weight: 700;">26.10</td>
                    <td>11.00</td>
                    <td style="color: #d4af37; font-weight: 700;">24.32</td>
                    <td>30.96</td>
                    <td style="color: #28a745; font-weight: 700;">51.90</td>
                    <td style="color: #d4af37; font-weight: 700;">24.08</td>
                    <td>28.82</td>
                  </tr>
                  <tr style="background-color: #e8f4f8; font-weight: 600;">
                    <td><strong>ZoomSearch (Ours)</strong></td>
                    <td>-</td>
                    <td>Dynamic</td>
                    <td style="color: #28a745; font-weight: 700;">62.53</td>
                    <td style="color: #d4af37; font-weight: 700;">17.32</td>
                    <td style="color: #28a745; font-weight: 700;">28.50</td>
                    <td>15.90</td>
                    <td style="color: #28a745; font-weight: 700;">24.75</td>
                    <td style="color: #d4af37; font-weight: 700;">37.80</td>
                    <td>50.12</td>
                    <td style="color: #28a745; font-weight: 700;">26.43</td>
                    <td style="color: #28a745; font-weight: 700;">32.92</td>
                  </tr>
                  <tr style="background-color: #fff3cd; font-style: italic;">
                    <td><em>Improvements</em></td>
                    <td>-</td>
                    <td>-</td>
                    <td style="color: #dc3545; font-weight: 700;">+25%</td>
                    <td style="color: #dc3545; font-weight: 700;">+48%</td>
                    <td style="color: #dc3545; font-weight: 700;">+31%</td>
                    <td style="color: #dc3545; font-weight: 700;">+42%</td>
                    <td style="color: #dc3545; font-weight: 700;">+29%</td>
                    <td style="color: #dc3545; font-weight: 700;">+18%</td>
                    <td style="color: #dc3545; font-weight: 700;">+10%</td>
                    <td style="color: #dc3545; font-weight: 700;">+54%</td>
                    <td style="color: #dc3545; font-weight: 700;">+26%</td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>

          <!-- MME-RealWorld-RS Results Table -->
          <div class="content mt-6">
            <h3 class="title is-4">Performance on MME-RealWorld-RS Dataset</h3>
            
            
            <div style="overflow-x: auto; display: flex; justify-content: center;">
              <table class="table is-bordered is-striped is-hoverable" style="font-size: 0.9rem; max-width: 800px;">
                <thead>
                  <tr style="background-color: #f5f5f5;">
                    <th>Method</th>
                    <th>Max Res.</th>
                    <th>Position</th>
                    <th>Color</th>
                    <th>Count</th>
                    <th>Avg.</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>Gemini-2.5-Flash</td>
                    <td>-</td>
                    <td>55.43</td>
                    <td>50.92</td>
                    <td>29.64</td>
                    <td>45.33</td>
                  </tr>
                  <tr>
                    <td>GPT-4o</td>
                    <td>-</td>
                    <td>33.52</td>
                    <td>29.83</td>
                    <td>18.90</td>
                    <td>27.42</td>
                  </tr>
                  <tr>
                    <td>LLaVA-v1.5-7b</td>
                    <td>336</td>
                    <td>21.48</td>
                    <td>22.95</td>
                    <td>16.31</td>
                    <td>20.28</td>
                  </tr>
                  <tr>
                    <td>LLaVA-v1.6-7b</td>
                    <td>672</td>
                    <td>26.49</td>
                    <td>24.06</td>
                    <td>20.47</td>
                    <td>23.70</td>
                  </tr>
                  <tr>
                    <td>LLaVA-ov-7b</td>
                    <td>384</td>
                    <td>26.81</td>
                    <td>26.14</td>
                    <td>27.57</td>
                    <td>26.83</td>
                  </tr>
                  <tr>
                    <td>Qwen2.5-VL-7b</td>
                    <td>1000</td>
                    <td>22.12</td>
                    <td>15.54</td>
                    <td>14.93</td>
                    <td>17.55</td>
                  </tr>
                  <tr>
                    <td>LLaVA-HR</td>
                    <td>1536</td>
                    <td>35.56</td>
                    <td>44.30</td>
                    <td>7.91</td>
                    <td>29.26</td>
                  </tr>
                  <tr>
                    <td>GeoChat</td>
                    <td>504</td>
                    <td>25.06</td>
                    <td>23.11</td>
                    <td>15.66</td>
                    <td>21.32</td>
                  </tr>
                  <tr>
                    <td>VHM</td>
                    <td>336</td>
                    <td>35.24</td>
                    <td>20.32</td>
                    <td>16.80</td>
                    <td>24.18</td>
                  </tr>
                  <tr>
                    <td>GeoLLaVA-8K</td>
                    <td>8K</td>
                    <td>34.90</td>
                    <td>27.92</td>
                    <td>22.27</td>
                    <td>28.41</td>
                  </tr>
                  <tr>
                    <td>ImageRAG</td>
                    <td>Dynamic</td>
                    <td>63.33</td>
                    <td>60.48</td>
                    <td>32.46</td>
                    <td>52.09</td>
                  </tr>
                  <tr>
                    <td>ZoomEye</td>
                    <td>Dynamic</td>
                    <td>43.52</td>
                    <td>60.88</td>
                    <td>30.10</td>
                    <td>44.94</td>
                  </tr>
                  <tr>
                    <td>RAP</td>
                    <td>Dynamic</td>
                    <td style="color: #d4af37; font-weight: 700;">57.62</td>
                    <td style="color: #d4af37; font-weight: 700;">64.53</td>
                    <td style="color: #28a745; font-weight: 700;">40.25</td>
                    <td style="color: #d4af37; font-weight: 700;">54.20</td>
                  </tr>
                  <tr style="background-color: #e8f4f8; font-weight: 600;">
                    <td><strong>ZoomSearch (Ours)</strong></td>
                    <td>Dynamic</td>
                    <td style="color: #28a745; font-weight: 700;">67.62</td>
                    <td style="color: #28a745; font-weight: 700;">66.14</td>
                    <td style="color: #d4af37; font-weight: 700;">39.15</td>
                    <td style="color: #28a745; font-weight: 700;">57.64</td>
                  </tr>
                  <tr style="background-color: #fff3cd; font-style: italic;">
                    <td><em>Improvements</em></td>
                    <td>-</td>
                    <td style="color: #dc3545; font-weight: 700;">+152%</td>
                    <td style="color: #dc3545; font-weight: 700;">+153%</td>
                    <td style="color: #dc3545; font-weight: 700;">+42%</td>
                    <td style="color: #dc3545; font-weight: 700;">+115%</td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Experiment Results Section -->

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Case Study</h2>

          <div id="results-carousel" class="carousel results-carousel">
            <div class="item">
              <img src="static/images/qualitative1.png" alt="Adaptive zoom search visualization" loading="lazy" style="max-width: 70%; margin: 0 auto; display: block;"/>
              <h2 class="subtitle has-text-centered">
                Qualitative comparison between our method and other search-based methods on an object counting task.
              </h2>
            </div>
            <div class="item">
              <img src="static/images/qualitative2.png" alt="VQA results comparison" loading="lazy" style="max-width: 70%; margin: 0 auto; display: block;"/>
              <h2 class="subtitle has-text-centered">
                Qualitative comparison between our method and other search-based methods on an object color recognition task.
              </h2>
            </div>
            <div class="item">
              <img src="static/images/good_cases.png" alt="VQA results comparison" loading="lazy" style="max-width: 96%; margin: 0 auto; display: block;"/>
              <h2 class="subtitle has-text-centered">
                 More qualitative results of ZoomSearch.
              </h2>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End image carousel -->



<!--BibTex citation -->
  <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <div class="bibtex-header">
      <h2 class="title">BibTeX</h2>
    </div>
    <pre id="bibtex-code"><code>@article{ZoomSearch,
  title={Look Where It Matters: Training-Free Ultra-HR Remote Sensing VQA via Adaptive Zoom Search},
  author={Zhou, Yunqi and Jiang, Chengjie and Yuan, Chun and Li, Jing},
  journal={arXiv preprint arXiv:2511.20460},
  year={2025}
}</code></pre>
  </div>
</section>

<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
